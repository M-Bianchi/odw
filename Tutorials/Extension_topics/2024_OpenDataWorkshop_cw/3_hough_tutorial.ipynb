{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-2G6RaheH0g"
   },
   "source": [
    "# The frequency-Hough transform tutorial\n",
    "### Searching for continuous gravitational waves from isolated, asymmetricly rotating neutron stars\n",
    "Andrew L. Miller\n",
    "\n",
    "National Institute for Subatomic Physics / Utrecht University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQXRCxmdvJn-"
   },
   "source": [
    "#### Searches for continuous waves from isolated, deformed neutron stars are broadly classified into three forms, depending on how much we know about the source: targeted (known position, rotational frequency and spin-down), directed (known position, unknown frequency/spin-down) and all-sky (all parameters unknown).\n",
    "\n",
    "#### There are benefits and drawbacks to each kind of search -- see arXiv:2206.06447 for a recent review.\n",
    "\n",
    "###### This tutorial will focus on a particular algorithm for all-sky searches for continuous gravitational waves: the frequency-Hough transform. This method maps points in the time/frequency plane of the detector to lines in the frequency/spin-down plane of the source. See arXiv:1407.8333 for more details.\n",
    "\n",
    "#### Note: The frequency-Hough transform algorithm and its implementation for CW searches has been designed and implemented for real searches by the Virgo Rome group of the LVK collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvc75NN_eH0k"
   },
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E5g-ofC4YWwT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyhough\n",
      "  Downloading pyhough-0.0.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading pyhough-0.0.3-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: pyhough\n",
      "Successfully installed pyhough-0.0.3\n",
      "Collecting pyfstat\n",
      "  Downloading PyFstat-2.1.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: attrs in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (23.2.0)\n",
      "Requirement already satisfied: corner in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (2.2.2)\n",
      "Requirement already satisfied: dill in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (0.3.8)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (3.7.3)\n",
      "Requirement already satisfied: numpy<2.0 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (1.24.4)\n",
      "Collecting pathos (from pyfstat)\n",
      "  Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: ptemcee in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (1.0.0)\n",
      "Requirement already satisfied: scipy in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (1.9.3)\n",
      "Requirement already satisfied: tqdm in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from pyfstat) (4.66.2)\n",
      "Collecting versioneer (from pyfstat)\n",
      "  Downloading versioneer-0.29-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: lalsuite>=7.13 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from lalsuite[lalpulsar]>=7.13->pyfstat) (7.21)\n",
      "\u001b[33mWARNING: lalsuite 7.21 does not provide the extra 'lalpulsar'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: contourpy>=1.0.1 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from matplotlib>=3.3->pyfstat) (6.4.0)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->pyfstat)\n",
      "  Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->pyfstat)\n",
      "  Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.16 (from pathos->pyfstat)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3->pyfstat) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mdubois/miniconda3/envs/igwn-py39/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->pyfstat) (1.16.0)\n",
      "Downloading PyFstat-2.1.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading versioneer-0.29-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: versioneer, ppft, pox, multiprocess, pathos, pyfstat\n",
      "Successfully installed multiprocess-0.70.16 pathos-0.3.2 pox-0.3.4 ppft-1.7.6.8 pyfstat-2.1.0 versioneer-0.29\n"
     ]
    }
   ],
   "source": [
    "# this will take a few minutes on first run, then should use cached files and be fast\n",
    "!pip install pyhough\n",
    "!pip install pyfstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "92Sj8pS2Y3I-"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#----------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Setting up the environment\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#----------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/2024_OpenDataWorkshop_cw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#----------------------\n",
    "# Setting up the environment\n",
    "#----------------------\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/2024_OpenDataWorkshop_cw\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SzpMbVqS0Ag"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyfstat\n",
    "import lal\n",
    "lal.swig_redirect_standard_output_error(False)\n",
    "import numpy as np\n",
    "import pyhough\n",
    "from pyhough import pm\n",
    "from pyhough import hm\n",
    "#### for some reason pm and hm need to be imported separately\n",
    "# make sure to put these after the pyfstat import, to not break notebook inline plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91bGIO9qjItP"
   },
   "source": [
    "\n",
    "# Simulate a CW signal and compute a spectrogram\n",
    "\n",
    "Compute the spectrogram of a set of SFTs. This is useful to produce\n",
    "visualizations of the Doppler modulation of a CW signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5adDk-ljbuC"
   },
   "outputs": [],
   "source": [
    "# general setup\n",
    "label = \"PyhoughExample\"\n",
    "outdir = os.path.join(\"Mockdata\", label)\n",
    "logger = pyfstat.set_up_logger(label=label, outdir=outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1-eQMxRjadC"
   },
   "outputs": [],
   "source": [
    "# properties of the GW data\n",
    "sftfilepath = \"Mockdata/H-7008_H1_1800SFT_SingleDetectorGaussianNoiseSignalInjected-1238166018-12614400.sft\"\n",
    "tstart = 1238166018\n",
    "duration = 0.4 * 365 * 86400\n",
    "detectors = \"H1\"\n",
    "Tsft = 1800\n",
    "depth = 5\n",
    "sqrtSX = 1.0e-23\n",
    "inj = {\n",
    "    \"F0\": 100.0,\n",
    "    \"F1\": -1e-9,\n",
    "    \"F2\": 0.0,\n",
    "    \"Alpha\": 0.0,\n",
    "    \"Delta\": 0.0,\n",
    "    \"h0\": sqrtSX / depth,\n",
    "    \"cosi\": 1,\n",
    "    \"psi\": 0.0,\n",
    "    \"phi\": 0.0,\n",
    "    \"tref\": tstart\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXxJUyhJjZjA"
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "logger.info(\"Loading SFT data and computing normalized power...\")\n",
    "freqs, times, sft_data = pyfstat.utils.get_sft_as_arrays(sftfilepath)\n",
    "sft_power = sft_data[\"H1\"].real ** 2 + sft_data[\"H1\"].imag ** 2\n",
    "normalized_power = (\n",
    "    2 * sft_power / (Tsft * sqrtSX ** 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wbwe3uGseH0n"
   },
   "source": [
    "# Plot spectrogram with plot_triplets function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIv-L-MNeH0o"
   },
   "source": [
    "Here, we can make out two modulations. One is due to the instrinsic spin-down of the source, and the other is due to the relative motion of the earth around the sun w.r.t. the source.\n",
    "\n",
    "In equations, the frequency evolution of the signal can be described as:\n",
    "\n",
    "\\begin{equation}\n",
    "f(t) = \\left(f_0+\\dot{f}(t-t_0)\\right)\\left(1+\\frac{\\vec{v}\\cdot\\hat{n}}{c}\\right) \\tag{1}\n",
    "\\end{equation}\n",
    "where $f_0$ is the emitted GW frequency at the time $t_0$, $\\vec{v}$ is the velocity of the detector, $\\hat{n}$ is the unit vector between the earth and the source.\n",
    "\n",
    "$f(t)$ is the measured frequency at time $t$, and is what is plotted in the time/freuqency maps below.\n",
    "\n",
    "We are interested in obtaining the source parameters, that is, the GW frequency $f_0$ and the spin-down $\\dot{f}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Q3yjbaWeH0o"
   },
   "outputs": [],
   "source": [
    "flat_times,flat_freqs,flat_pows = pyhough.pm.flatten_spectrogram(times[\"H1\"],freqs,normalized_power)\n",
    "pyhough.pm.python_plot_triplets((flat_times-flat_times[0])/86400,flat_freqs,flat_pows,'.',label='equalized power')\n",
    "plt.xlabel('time (days)',size=14)\n",
    "plt.ylabel('frequency (Hz)',size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FedEwtuZF-sf",
    "outputId": "905c2c4f-929b-4405-8eec-fa46df83491c"
   },
   "source": [
    "# Create peakmap from spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytmi5o40eH0o"
   },
   "source": [
    "Here, we take the spectrogram computed in PyFstat, and, in each Fast Fourier Transform (that is, at each time in the spectrogram), select local maxima above a chosen threshold. The local maxima criteria reduce the impact of noise lines that may pollute multiple adjacent frequency bins.\n",
    "\n",
    "We call the resulting thresholded spectrogram a \"peakmap\", where each surviving time/frequency pixel is called a \"peak\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oigyRfRbeH0o"
   },
   "source": [
    "#### Setting threshold on peak selection to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QulxCV8heH0o"
   },
   "outputs": [],
   "source": [
    "threshold = 3 # need to apply a threshold on equalized power and select maxima above this threshold to run Hough\n",
    "pm_times,pm_freqs,pm_pows,index = pyhough.pm.make_peakmap_from_spectrogram(times[\"H1\"],freqs,normalized_power,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNRzb-LdFpSR"
   },
   "outputs": [],
   "source": [
    "pyhough.pm.python_plot_triplets((pm_times-pm_times[0])/86400,pm_freqs,pm_pows,'.',label='equalized power')\n",
    "plt.xlabel('time (days)',size=14)\n",
    "plt.ylabel('frequency (Hz)',size=14);\n",
    "# plt.ylim([99.98,100.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uqrAgH5eH0o"
   },
   "source": [
    "# Create source position vector and get detector velocities for Dopp Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjbjDS5FeH0o"
   },
   "outputs": [],
   "source": [
    "# source position and detector velocities\n",
    "writer_kwargs = {\n",
    "    \"label\": \"SingleDetectorGaussianNoiseSignalInjected\",\n",
    "    \"outdir\": \"Mockdata\",\n",
    "    \"tstart\": 1238166018,\n",
    "    \"duration\": 0.4 * 365 * 86400,\n",
    "    \"detectors\": \"H1\",\n",
    "    \"sqrtSX\": sqrtSX,\n",
    "    \"Tsft\": 1800,\n",
    "    \"SFTWindowType\": \"tukey\",\n",
    "    \"SFTWindowParam\": 0.01,\n",
    "}\n",
    "writer = pyfstat.Writer(**writer_kwargs, **inj)\n",
    "position = [inj[\"Alpha\"], inj[\"Delta\"]]\n",
    "vec_n = pyhough.pm.astro2rect(position,1)\n",
    "ts,vs = pyhough.pm.get_detector_velocities(writer)\n",
    "Nts = len(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-Wpl5AJeH0p"
   },
   "source": [
    "# Remove Doppler shift from peakmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfx_ik5deH0p"
   },
   "source": [
    "To search for a continuous wave coming from a particular sky location, we \"point\" our detector by correcting the data for the Doppler shift induced by the relative motion of earth and the source. In this method, the Doppler correction is a shifting of the time/frequency peaks in the peakmap for a given sky location.\n",
    "\n",
    "Essentially, this corresponds to the following\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{f(t)}{\\left(1+\\frac{\\vec{v}\\cdot\\hat{n}}{c}\\right)} = f_0 +\\dot{f}(t-t_0) \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Now, the new frequency is simply:\n",
    "\n",
    "\\begin{equation}\n",
    "f_{\\rm new}(t) = f_0 + \\dot{f}(t-t_0)\n",
    "\\end{equation}\n",
    "\n",
    "and we can apply the frequency-Hough Transform to search for this modulation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C43eRtfWeH0p"
   },
   "outputs": [],
   "source": [
    "pm_freqs_undop = pyhough.pm.remove_doppler_from_peakmap(pm_times,pm_freqs,index,vec_n,vs,Nts) # Eq. 2\n",
    "pyhough.pm.python_plot_triplets((pm_times-pm_times[0])/86400,np.array(pm_freqs_undop),pm_pows,'.',label='equalized power')\n",
    "# plt.ylim([99.989,100.002]);\n",
    "plt.xlabel('time (days)',size=14)\n",
    "plt.ylabel('frequency (Hz)',size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbqMFqD4eH0p"
   },
   "source": [
    "# Analysis and relevant signal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNFHGf6eeH0p"
   },
   "outputs": [],
   "source": [
    "alltimes = times[\"H1\"] ### the times of the analysis\n",
    "df = 1/Tsft # the frequency bin size\n",
    "ref_perc_time = 0.0 * 100 # reference time for the Hough at which f0 is determined, set any number between 0 (beginning), 100 (end)\n",
    "sig_fdot = inj['F1'] #spin-down of injected signal\n",
    "dsd = 1/(Tsft * duration) # step in spin-down: dsd = df / Tobs\n",
    "sdgrid = pyhough.hm.make_sd_grid(sig_fdot,dsd) ## grid of spin-downs to search over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0_CkSHA_fdH"
   },
   "source": [
    "# Run frequency-Hough on Doppler corrected peakmap and plot Hough map\n",
    "\n",
    "\n",
    "The input is the time/frequency peakmap, which is simply a collection of ones. For given choices of $\\dot{f}$, we solve for $f_0$\n",
    "\n",
    "\\begin{equation}\n",
    "f_0 = f_{\\rm new}-\\dot{f}(t-t_0)\n",
    "\\end{equation}\n",
    "\n",
    "We thus need to specify a range of $\\dot{f}$ values with a particular spacing, given by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta\\dot{f} = df/T_{\\rm obs}\n",
    "\\end{equation}\n",
    "where $\\delta f=1/T_{\\rm FFT}$ and $T_{\\rm FFT}$ is the FFT length (1800 s in this case), and specify a maximum and minimum $\\dot{f}$ to search over.\n",
    "\n",
    "The Hough sums ones along the time/frequency tracks of the signals, NOT the equalized power on the color axis that is seen in the peakmap plots\n",
    "\n",
    "The output of this code $\\texttt{hmap_from_pm}$ is a 2-dimensional histogram in the $f_0$/$\\dot{f}$ plane of the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R42xjbFweH0p"
   },
   "outputs": [],
   "source": [
    "hmap_from_pm = pyhough.hm.hfdf_hough(pm_times,pm_freqs_undop,Tsft,sdgrid,ref_perc_time)\n",
    "fs_for_hmap_from_pm = np.arange(np.min(pm_freqs_undop),np.max(pm_freqs_undop),df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFHbPPe4eH0p"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()#figsize=(0.8 * 16, 0.8 * 9))\n",
    "ax.set(ylabel=\"Spin-down [Hz/s]\", xlabel=r\"Frequency [Hz]\")#, ylim=(99.98, 100.02))\n",
    "c = ax.pcolormesh(\n",
    "    fs_for_hmap_from_pm,\n",
    "    sdgrid,\n",
    "    hmap_from_pm,\n",
    "    cmap=\"inferno\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "fig.colorbar(c, label=\"number count\")\n",
    "plt.tight_layout()\n",
    "# ax.set(ylim=(sig_fdot*1.3,-0.7e-9));\n",
    "ax.set(xlim=(99.975,100.025));\n",
    "plt.savefig(os.path.join(outdir, label + \"_hm_map.png\"), format='png',dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwf1YMWaEdUZ"
   },
   "outputs": [],
   "source": [
    "# Zoom in at peak\n",
    "fig, ax = plt.subplots()#figsize=(0.8 * 16, 0.8 * 9))\n",
    "ax.set(ylabel=\"Spin-down [Hz/s]\", xlabel=r\"Frequency [Hz]\")#, ylim=(99.98, 100.02))\n",
    "c = ax.pcolormesh(\n",
    "    fs_for_hmap_from_pm,\n",
    "    sdgrid,\n",
    "    hmap_from_pm,\n",
    "    cmap=\"inferno\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "fig.colorbar(c, label=\"number count\")\n",
    "plt.tight_layout()\n",
    "ax.set(ylim=(inj[\"F1\"] - 20*dsd, inj[\"F1\"] + 20*dsd));\n",
    "ax.set(xlim=(99.975,100.025));\n",
    "plt.savefig(os.path.join(outdir, label + \"_hm_map_zoom.png\"), format='png',dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzaDDLfWeH0p"
   },
   "source": [
    "Q1: Why are there seemingly negative slopes of the lines in this map? Can you guess which parameter you need to change to obtain all positive slopes or a mix of positive and negative sloped lines?\n",
    "\n",
    "Q2: If the true signal frequency and spin-down are  F0 and F1, respectively, why are there multiple pixels in this map surrounding the true values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYJ6RwMZxxmK",
    "outputId": "84d040a3-8d88-4295-9469-e6d184f07f8e"
   },
   "source": [
    "# Apply wrong Doppler correction to peakmap, run Hough, and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27F5bhxiQyKX"
   },
   "outputs": [],
   "source": [
    "wrong_position = [np.pi/3, np.pi/4]\n",
    "wrong_vec_n = pyhough.pm.astro2rect(wrong_position,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APtSOi8MeH0p"
   },
   "outputs": [],
   "source": [
    "pm_freqs_undop_wrong = pyhough.pm.remove_doppler_from_peakmap(pm_times,pm_freqs,index,wrong_vec_n,vs,Nts)\n",
    "pyhough.pm.python_plot_triplets((pm_times-pm_times[0])/86400,np.array(pm_freqs_undop_wrong),pm_pows,'.',label='equalized power')\n",
    "# plt.ylim([99.989,100.002]);\n",
    "plt.xlabel('time (days)',size=14)\n",
    "plt.ylabel('frequency (Hz)',size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvRqFZx1eH0q"
   },
   "source": [
    "Q3: Do you see the difference between using the wrong and correct source positions to correct the peakmap? What can you conclude about the ability of this method to localize sources in the sky?\n",
    "\n",
    "Q4: What do you think will happen to a monochromatic noise line after the Doppler correction is applied? Is this good or not? Why?\n",
    "\n",
    "\n",
    "Comment: Noise line is one of the non-Gaussian noise. It can be modeled by a sinusoidal waveform in the detector frame:\n",
    "\n",
    "$$ h_\\mathrm{line}(t) = A \\sin(2\\pi f_\\mathrm{line} t + \\phi_\\mathrm{line}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHbpk4kGRuP0"
   },
   "outputs": [],
   "source": [
    "# ### run Hough with wrong position\n",
    "hmap_wrong_pos = pyhough.hm.hfdf_hough(pm_times,pm_freqs_undop_wrong,Tsft,sdgrid,ref_perc_time)\n",
    "fs_for_hmap_from_spec_wrong_position = np.arange(np.min(pm_freqs_undop_wrong),np.max(pm_freqs_undop_wrong),df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hItbrJB5eH0q"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()#figsize=(0.8 * 16, 0.8 * 9))\n",
    "ax.set(ylabel=\"Spin-down [Hz/s]\", xlabel=r\"Frequency at $t_0$ [Hz]\")#, ylim=(99.98, 100.02))\n",
    "c = ax.pcolormesh(\n",
    "    fs_for_hmap_from_spec_wrong_position,\n",
    "    sdgrid,\n",
    "    hmap_wrong_pos,\n",
    "    cmap=\"inferno\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "fig.colorbar(c, label=\"number count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir, label + \"_hm_map_wrongposition.png\"), format='png',dpi=400)\n",
    "# ax.set(ylim=(sig_fdot*2,-sig_fdot*1.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rkV6lxZeH0q"
   },
   "source": [
    "Q5: Compare the peak number count at the source frequency and spin-down in this Hough map and the one run on the properly corrected peakmap. Why is there a reduction in the number count?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4bScSLuRxig"
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYfqNIUhTktd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
